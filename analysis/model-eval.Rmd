# Model Evaluation


## Variable Importance

Records notes on variable importance (VI) measures for random forests. May drift into other evaluation methods.

Brandon Greenwell (who authored the `pdp` package) has an R package `vip` for variable importance measures. It is on [CRAN](https://cran.r-project.org/web/packages/vip/index.html) but there is more information and articles on the [package website](https://koalaverse.github.io/vip/index.html). There is also a [paper](https://arxiv.org/abs/1805.04755) connected to this work. The authors have a [book chapter](https://bradleyboehmke.github.io/HOML/iml.html) on interpretable machine learning which includes VI. The Interpretable Machine Learning book has a [section on variable importance](https://christophm.github.io/interpretable-ml-book/feature-importance.html).

The notes below are taken from these (I won't give exact references in most cases).

Some modelling methods have *model-specific* measures of importance which can only be used with that specific model class, while other methods must rely on *model-agnostic* approaches. 

**TBC**

## Misc

[Model Explanation System](http://www.blackboxworkshop.org/pdf/Turner2015_MES.pdf) and [MES update](https://arxiv.org/pdf/1606.09517.pdf). Method for explaining complex ML model output.

[Brier Score](https://en.m.wikipedia.org/wiki/Brier_score) This is score function that measures the accuracy of probabilistic predictions for discrete outcomes. Basically a mean squared error.

## Model Validation

I'll put some links here relating to handling test/training data splits (or cross-validation etc.).

+ [Random Test/Train Split is not Always Enough](http://www.win-vector.com/blog/2015/01/random-testtrain-split-is-not-always-enough/) Time based data might not want a random split.

## Loss Functions

+ [Binary cross-entropy/log loss](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a)

## ROC Curves

[R packages for ROC](https://rviews.rstudio.com/2019/03/01/some-r-packages-for-roc-curves/)

[ICML tutorial on ROC](http://people.cs.bris.ac.uk/~flach/ICML04tutorial//)

[ROC Curve, Lift Chart and Calibration Plot](http://www.stat-d.si/mz/mz3.1/vuk.pdf)

[Multiple ROC curves in ROCR](https://stackoverflow.com/questions/14085281/multiple-roc-curves-in-one-plot-rocr)
I adapted this to use with ggplot. Three methods:
```{r roclines, eval = F}
# There are 2 performance objects perf1 and perf2
#option 1
plot(perf1)
abline(0, 1, lty = 2)
lines(perf2@x.values[[1]], perf2@y.values[[1]], col = 2)

# option 2
plot(perf1)
abline(0, 1, lty = 2)
plot(perf2, add = TRUE, colorize = TRUE)

# ggplot option

rocdt <- tibble(x = c(perf1@x.values[[1]], perf2@x.values[[1]]), 
                y = c(perf1@y.values[[1]], glm = perf2@y.values[[1]]), 
                model = c(rep("A", length(perf1@x.values[[1]])), rep("B", length(perf2@x.values[[1]]))))
ggplot(rocdt, aes(x = x, y = y, col = model)) +
  geom_line() +
  geom_abline(slope = 1, intercept = 0, linetype = 2) +
  xlab("False Positive Rate") +
  ylab("True Positive Rate") +
  theme_minimal()
```


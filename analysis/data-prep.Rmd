# Data Preparation

## Importing & Exporting Data in R

### Base methods

Quick guide http://www.statmethods.net/input/importingdata.html

Comprehensive https://www.datacamp.com/community/tutorials/r-data-import-tutorial#gs.MWOdcL8

The basic function is `read.table()`. There are variants like `read.csv()` and `read.delim()` but these can all be done through `read.table()` with appropriate arguments.

You can import from the clipboard using `read.table("clipboard")`.  

Files can be downloaded from the web using `download.file(url, destfile, ...)`. The `destfile` is where to save. 

## Reading text from a text file

Can use `read.table()` for this but this reads it in as a data frame. To get raw text use either `readLines()` or `scan()`. See http://en.wikibooks.org/wiki/R_Programming/Text_Processing#Reading_and_writing_text_files

### readr package

For reading in data.  The first is used for csv, tab separated etc. and table formatted files. Are faster than base functions, have simpler arguments, and give more useful error messages.

readr supports seven file formats with seven read_ functions:

+	`read_csv()`: comma separated (CSV) files
+	`read_tsv()`: tab separated files
+	`read_delim()`: general delimited files
+	`read_fwf()`: fixed width files
+	`read_table()`: tabular files where colums are separated by white-space.
+	`read_log()`: web log files

Try these with just the file path first.

Comparison of `read_csv()` with`fread()`:

+ `read_csv()` misclassifies a lot of column types (but gives warnings). It bases type only on the top part of the column.
+ `fread()` is more thorough in getting column types, but encodes dates as characters.
+ `fread()` has an `na.strings` arg to automatically convert certain strings to NAs.
+ `fread()` is faster 
+ `fread()` outputs a data frame rather than a tibble.

## Other Packages

[The rio package](https://github.com/leeper/rio) gives a simple `import()` function which will use a different method depending on the file extension. It calls other packages such as data.table, haven, or readxl to do this.

[vroom](https://vroom.r-lib.org/index.html) is a tidyverse package that uses lazy loading to be very fast.

### readxl package

HW package for importing excel files. Not loaded with tidyverse. Two main functions:

+	excel_sheets(path) - lists all sheets in the spreadsheet.
+	read_excel(path, sheet,…) - used to read in data. Default is first sheet unless specified (by name or number).

The argument path is in quotations. 

Vignettes:

+	[Cell and column types](https://cran.r-project.org/web/packages/readxl/vignettes/cell-and-column-types.html) – by default read_excel() will guess column types but can be specified.
+	 [Sheet geometry](https://cran.r-project.org/web/packages/readxl/vignettes/sheet-geometry.html) – talks about how to specify the area of an excel sheet that is imported. By default it imports the smallest rectangle that contains non-empty cells but there are lots of options.

### Writing to Excel

I have had problems with this in the past due to Jave dependency issues for the packages I tried. However, when I revisited it recently (2020) it worked fine. The package I used was [openxlsx](https://cran.r-project.org/web/packages/openxlsx/). Another package which might be useful is [writexl](https://github.com/ropensci/writexl). I haven't tried this but it appears to be lightweight (without Excel dependency). It is probably able to only write basic data to teh spreadsheet though (e.g. no multiple sheets).

The basic function in the openxl package is `write.xlsx(x, file)`. Multiple sheets can be written by supplying a named list as `x`. Alternatively a workbook can be built up in detail using `createWorkbook()` and then adding layers. See the vignettes.

### XML

I've only done a bit on this. The package to use is [xml2](https://github.com/r-lib/xml2). The guide here was useful: [quick guide to XML in R](https://lecy.github.io/Open-Data-for-Nonprofit-Research/Quick_Guide_to_XML_in_R.html).

I am unclear on the structure for XML  but it seems to based on ideas from relational databases with a nested tag structure (thinking of trees might be helpful). Extracting is done with string pattern matching and searching up and down the hierarchy (parents and children).

## Data Processing

[Preparing data for classifiers](http://www.win-vector.com/blog/2014/12/a-comment-on-preparing-data-for-classifiers/). John Mount. I have downloaded the paper mentioned here.

[Variable Importance](https://win-vector.com/2018/12/17/vtreat-variable-importance/). Suggests that variable screening (before passing to model fitting) is important. Wide data can cause any algorithm to fail. The vtreat package has several functions to value the variables individually (using linear, piecewise linear, or knn fits).


[Advanced tricks with data table](https://brooksandrew.github.io/simpleblog/articles/advanced-data-table/)

[Speed Comparison for basic row/column operation](http://www.win-vector.com/blog/2019/05/timing-working-with-a-row-or-a-column-from-a-data-frame/). dplyr can be quite a bit slower than base R once the data frame gets to a decent size.

The [variablekey vignette](https://cran.r-project.org/web/packages/kutils/vignettes/variablekey.pdf) in the kutils package gives a method for recording changes in variables in data frames. It is based on a table of old/new variable names/classes/values (where the number of distinct values is not too large). The ordering of the values can be recorded. The table can be changed in, e.g. excel, then these changes can be applied to the data frame. I like the general idea of recording and displaying changes but I want to only make changes via R code.


### Missing Values

The `visdat::vis_miss()` could be useful for seeing quickly if missing values in different columns are in the same rows.

[Amelia package](https://www.rdocumentation.org/packages/Amelia/versions/1.7.4/topics/amelia) - creates imputed datasets using a bootstrap EM algorithm. 

[Chapter from Gelman on missing data](http://www.stat.columbia.edu/~gelman/arm/missing.pdf)

To replace empty strings with `NA` in a tibble use `mutate_all(df, ~na_if(.,""))` or `mutate_if(df, is_character, ~na_if(.,""))`.

[Removing NA values in a data frame](https://stackoverflow.com/questions/4862178/remove-rows-with-all-or-some-nas-missing-values-in-data-frame). 

+ `na.omit()` removes rows with any missing values.
+ `tidyr::drop_na()` does the same but has tidyselect option for columns to inspect for NAs. 
+ `complete.cases()` is base option to only consider some columns e.g. `df[complete.cases(df[ , 5:6]),]` only check columns 5 and 6 of `df`.



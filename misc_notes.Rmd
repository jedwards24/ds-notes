---
title: "Misc Notes"
output: html_document
---

This is a place for collecting links and small notes for which there isn't yet an appropriate document in which to put them.

## Functions to look at or use

+ `crossing()`, `separate()`, `extract()` - all tidyverse.
+ `cut()`, `hmisc::cut2()` - bucketing continuous values
+ `anyDuplicated()` - test for duplicated rows in selected columns in a data frame. 
+ `purrr::pluck()` - generalised form of `[[`.

## Tabulation functions

`table()` produces contingency table objects.  `addMargins()` and `prop.table()` work with table objects. Also `tabulate()` returns a named vector but only works with numeric or factor inputs. I wrote the following to get a table with vector object. Not sure if it is needed/useful.

```
vec_count <- function(x) {
  tab <- table(x)
  counts <- as.vector(tab)
  names(counts) <- names(tab)
  counts
}
```

## A/B Testing

[A/B testing links](http://www.win-vector.com/blog/2015/06/designing-ab-tests/)

[Multiworld testing](https://www.microsoft.com/en-us/research/project/multi-world-testing-mwt/). Bandit-based (?) alternative to A/B testing from microsoft.

[Why Multi-armed Bandit Algorithm is Not “Better” than A/B Testing](https://vwo.com/blog/multi-armed-bandit-algorithm/) Poor straw man argument against bandit use, but I am saving it because I suspect it is widely read. There is a commentary on this in [Why Multi-armed Bandit algorithms are superior to A/B testing](https://www.chrisstucchio.com/blog/2012/bandit_algorithms_vs_ab.html), but also see the later [Don't use bandit algorithms](https://www.chrisstucchio.com/blog/2015/dont_use_bandits.html) by the same author. 

## Elbow Points in Curves

Also called knee points. These can be used in situations of diminishing returns e.g. clustering, model fit with increasing complexity, or algorithm tuning. 

https://raghavan.usc.edu//papers/kneedle-simplex11.pdf
https://www.kaggle.com/kevinarvai/knee-elbow-point-detection

## Goodness-of-fit Tests

This concerns testing the fit of data against a distribution. I will only give notes about the chi-squared test here, but there other tests, such as the Kolmogorov–Smirnov test and the Cramér–von Mises criterion.

The chi-squared test usually refers to Pearson's chi-squared test, but this is part of a wider family of hypothesis tests based on chi-squared test statistics. Pearson's test is used to test for goodness of fit, homogeneity, and independence. See [wiki](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test) for basic details. 

I wanted to do a goodness-of-fit test (for Poisson fit). This can be done in base R using the `chisq.test()` function, but how to use it wasn't immediately obvious to me. The test statistic is found by comparing observed bin counts with the expected bin counts under the null (here a Poisson distribution with rate parameter given by the mean of the data). The formula for $k$ bins is $\sum^k_{i=1}(\frac{(O_i - E_i)^2}{E_i})$. Asymtoptically this will have a chi-squared distribution with $k-p-1$ degrees of freedom ($p$ the number of estimated parameters). This choice of number and location of the bins is an open question. The main aim in the choice is to satisfy the assumption of normality in the bin counts, which leads to the chi_squared test statistic. This leads to guidelines that the expected counts should (mostly) be at least 5. 

An alternative, which avoids this problem is to use Monte Carlo simulation, and this is implemented in `chisq.test()`. The observed counts are given as `x` and the expected probabilities as `p`. The test does not need to know what bins these counts represent. The `rescale.p=TRUE` argument will rescale  `p` to sum to one. Using these inputs will use the chi-squared test, but setting `simulate.p.value=TRUE` will instead use simulation. Samples are drawn under the null and the usual test statistic calculated. This gives a distribution of the test statistic under the null, and the observed test statistic can be located in this distribution to give a p-value.

There are functions in the tidymodels package infer `chisq_test()` and `chisq_stat()` which replicate `chisq.test()` in a tidy setting, but I had problems getting these to work for goodness-of-fit tests.

The code below gives an example pipeline for multiple tests using a nested data frame. The data `allw` has counts for each of week 1:51 over several years (columns `year`, `week`, `n`). I wanted to perform a separate test for each year.

```{r, eval=FALSE}
# Helper. Produces a table of probabilities under the null Poisson hypothesis.
# A row is given for each value from 0:max_n, and one for [max_n + 1: Inf).
get_pois <- function(df, max_n, rate) {
  count(df, n, name = "actual") %>% 
    complete(n = 0:max_n, fill = list(actual = 0)) %>% 
    mutate(dpois = dpois(n, rate)) %>% 
    add_row(n = max_n + 1, actual = 0, dpois = ppois(n - 1, rate, F))  
}

max_n <- max(all_w$n)
nested <- nest(allw, data = c(week, n)) %>% 
  mutate(weekly_mean = unlist(map(data, ~(mean(.$n))))) %>% 
  mutate(weekly_var = unlist(map(data, ~(var(.$n))))) %>% 
  mutate(pois_data = map2(.x = data, .y = weekly_mean, ~get_pois(df = .x, max_n = max_n, rate = .y))) %>% 
  mutate(chisq = map(.x = pois_data, 
                     ~chisq.test(x = .x$actual, p=.x$dpois, rescale.p=T, simulate.p.value=TRUE))) %>% 
  mutate(p_val = unlist(map(chisq, ~.$p.value)))
```

## Scheduling Tasks

[How to run R from the Windows Task Scheduler](https://www.r-bloggers.com/how-to-run-r-from-the-task-scheduler/). I had some difficulties adding the R folder to the Windows system path (I think I may need to restart the shell). [Path editing instructions are here](https://www.howtogeek.com/118594/how-to-edit-your-system-path-for-easy-command-line-access/). I need to add `C:\Program Files\R\R-3.6.3\bin\` (the folder containing Rscript, with appropriate version number).

Scheduling can also be done from within R using the [taskscheduleR package](https://cran.r-project.org/web/packages/taskscheduleR/).

[More on the windows task scheduler](https://www.dummies.com/computers/pcs/how-to-open-windows-task-scheduler/).

[Scheduling R Markdown reports via R](https://beta.rstudioconnect.com/content/3132/Job_Scheduling_R_Markdown_Reports_via_R.html)

## Paths

[R for DS workflow chapter](https://r4ds.had.co.nz/workflow-projects.html) says never to use absolute paths in scripts. Gives differences in paths between mac/linux and windows: 

+ Absolute paths in Windows start with a drive letter (`C:`) or two backslashes, while in Mac/Linux they start with a slash.
+ `~` is a shortcut to the home directory in Mac/Linux, but to Documents in Windows.

## Misc Links

[http://www.win-vector.com/blog/2015/02/does-balancing-classes-improve-classifier-performance/](Balancing classifiers)

[Scalable bootstrap video](https://www.youtube.com/watch?v=9v6cMnFNiOI&index=1&list=PLi_-RNsPXDTKXADPyrSVAgAhtiIkV04hY) with [slides](https://www.rss.org.uk/Images/PDF/events/2017/M_Jordan%20260417.ppt). Michael Jordan

https://data36.com/data-coding-101-introduction-bash/. Intro to bash coding.

[Measuring Bernoulli Probabilities in the Presence of Delayed Reactions](https://www.chrisstucchio.com/blog/2016/delayed_reactions.html)

[Functional sequences using magrittr](https://blog.rstudio.com/2014/12/01/magrittr-1-5/). You can use `myfun <- . %>% ...` to create a function-like *functional sequence*.

[Difference between print(), cat(), message(), warning(), stop()](https://stackoverflow.com/questions/36699272/why-is-message-a-better-choice-than-print-in-r-for-writing-a-package). Output from `message()` is treated differently from print/cat and so can be identified as a message for error checking. Also displayed in a different colour.

[Hash tables in R](https://jeffreyhorner.tumblr.com/post/117059271933/hash-table-performance-in-r-part-iv). Four part blog series looks at hashing implementations in R and finds best performance using environments. There is a [hash package](https://cran.r-project.org/web/packages/hash/index.html). 

[Some methods for testing for equality of all elements of a numeric vector](https://stackoverflow.com/questions/4752275/test-for-equality-among-all-elements-of-a-single-vector). I looked into this with functional dependencies.

**Partial unlisting**. `unlist()` has `recursive` and `use.names` arguments. `recursive = FALSE` is useful if you only want to remove the first level of the list. See `purrr::flatten()` for alternative (type stable).

[Removing NA values in a data frame](https://stackoverflow.com/questions/4862178/remove-rows-with-all-or-some-nas-missing-values-in-data-frame). 

+ `na.omit()` removes rows with any missing values.
+ `tidyr::drop_na()` does the same but has tidyselect option for columns to inspect for NAs. 
+ `complete.cases()` is base option to only consider some columns e.g. `df[complete.cases(df[ , 5:6]),]` only check columns 5 and 6 of `df`.

**Style for table captions**. There wasn't a clear answer to whether to use title or sentence case in tabel/plot captions except to be consistent. Perhaps sentence case in captions and title case in titles?

+ [Full stops at end of captions](https://english.stackexchange.com/questions/121551/caption-text-punctuation-full-stops-always-necessary-at-the-end). Says this depends on house style. One suggestion is to omit for short sentence fragments but use for full sentences. But the same source says this could be trumped by consistency.
+ [Which words to capitalise in a title](https://english.stackexchange.com/questions/14/which-words-in-a-title-should-be-capitalized). 
